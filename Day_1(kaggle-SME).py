# -*- coding: utf-8 -*-
"""SME.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1shNTNVAKKhk0_WA-ZCb9X9CoBAICvYLF
"""

!pip install -U -q PyDrive ## you will have install for every colab session

     from pydrive.auth import GoogleAuth
     from pydrive.drive import GoogleDrive
     from google.colab import auth
     from oauth2client.client import GoogleCredentials

     # 1. Authenticate and create the PyDrive client.
     auth.authenticate_user()
     gauth = GoogleAuth()
     gauth.credentials = GoogleCredentials.get_application_default()
     drive = GoogleDrive(gauth)

from google.colab import drive
drive.mount('/content/drive')

!ls

import os
from google.colab import files

os.chdir("drive/My Drive/TCS")

"""#**IMPORTING DATA**"""

import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt 
#import turicreate as tc

df = pd.read_csv("Train_psolI3n.csv")
df1 = pd.DataFrame(df)
print(df1.isnull().sum())
print(df1.head())
df1 = df1.dropna()
print(df1.isnull().sum())

df2 = pd.read_csv("Test_09JmpYa.csv")
print(df2.columns)
df2.drop(['Customer_Location','Email_Campaign_Type','Time_Email_sent_Category'],1,inplace=True)
df2.head()

"""#**EMAIL SOURCE COUNT**"""

#df1 = pd.DataFrame(df)
#print(df1.axes)
#df1 = df1.drop(columns=['Customer_Location','Email_Campaign_Type','Time_Email_sent_Category'],axis=1)

import seaborn as sn
import matplotlib.pyplot as plt

one = len(df1[df1['Email_Source_Type']==1])
two = len(df1[df1['Email_Source_Type']==2])

label0 = ['1','2']
li0 = [one,two]
index0= np.arange(len(label0))

sn.set(style="darkgrid")
sn.barplot(index0,li0)
plt.xlabel('SOURCE OF EMAIL',fontsize=14)
plt.ylabel('Count',fontsize=12)
plt.xticks(index0,label0,fontsize=14)
plt.show()

"""# **TIME EMAIL SENT**"""

import pandas as pd
import numpy as np
import seaborn as sn
import matplotlib.pyplot as plt

one = len(df1[df1['Time_Email_sent_Category']==1])
two = len(df1[df1['Time_Email_sent_Category']==2])
three = len(df1[df1['Time_Email_sent_Category']==3])

label00 = ['1','2','3']
li00 = [one,two,three]

index00 = np.arange(len(label00))

sn.set(style='darkgrid')
sn.barplot(index00,li00)
plt.xlabel('TIME EMAIL SENT',fontsize=14)
plt.ylabel('COUNT',fontsize=12)
plt.xticks(index00,label00,fontsize=14)
plt.show()

"""#**EMAIL STATUS**"""

import numpy as np
import seaborn as sn

ignored = len(df1[df1['Email_Status']==0])
read  = len(df1[df1['Email_Status']==1])
acknowledge = len(df1[df1['Email_Status']==2])

print("IGNORED:",ignored)
print("READ:",read)
print("Acknowledge:",acknowledge)

label1 = ['0','1','2']
li1 = [ignored,read,acknowledge]

index1 = np.arange(len(label1))

sn.set(style="darkgrid")
sn.barplot(index1,li1)
plt.xlabel('Mail-Tracking',fontsize =14)
plt.ylabel('Count',fontsize =12)
plt.xticks(index1,label1,fontsize=12)
plt.show()

print(df1.head())
print(df1['Email_Status'].agg(['nunique']))

"""# **CUSTOMER LOCATION**"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sn

A = len(df1[df1['Customer_Location']=='A'])
B = len(df1[df1['Customer_Location']=='B'])
C = len(df1[df1['Customer_Location']=='C'])
D = len(df1[df1['Customer_Location']=='D'])
E = len(df1[df1['Customer_Location']=='E'])
F = len(df1[df1['Customer_Location']=='F'])
G = len(df1[df1['Customer_Location']=='G'])

label2 = ['A','B','C','D','E','F','G']
li2 = [A,B,C,D,E,F,G]

sn.set(style="darkgrid")
index2 = np.arange(len(label2))
sn.barplot(index2,li2)
plt.xlabel('CUSTOMER LOCATION',fontsize=14)
plt.ylabel('FREQUENCY',fontsize=12)
plt.xticks(index2,label2,fontsize=14)
plt.show()

"""#**PAST COMMUNICATIONS**"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sn


class_0 = df1.loc[df1['Email_Type'] == 1]['Total_Past_Communications']
class_1 = df1.loc[df1['Email_Type'] == 2]['Total_Past_Communications']
plt.figure(figsize = (14,6))
plt.title('Total Past Communications (Destiny Plot)')
#sn.set_color_codes(pastel)
sn.distplot(class_1,kde=True,bins=200, color='red',label="1")
sn.distplot(class_0,kde=True,bins=200, color='green',label="2")
plt.show()

"""# **SUBJECT HOTNESS**"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sn

sn.stripplot(x=df1['Email_Type'],y=df1['Subject_Hotness_Score'],jitter=True)
plt.show()

"""#**CUSTOMER LOCATION INSIGHT**"""

import seaborn as sn
import matplotlib.pyplot as plt

df1 = df1.dropna()
val = ['A','B','C','D','E','F','G']
for i in val:
  pf =df1['Email_Type'].where(df1['Customer_Location']==i)
  print(pf.groupby(df1['Email_Type']).agg(['count']))



print(df1['Customer_Location'].agg(['count']))

df1.drop(['Customer_Location','Email_Campaign_Type','Time_Email_sent_Category'],1,inplace=True)

"""#**CONCATINATION**"""

import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer

df3 = pd.concat([df1,df2])
df3 = df3.dropna()
print(df3.head())

#imp = SimpleImputer(missing_values=,strategy='median')
#imp.fit(df3)

"""#**FEATURE SELECTION**"""

import sklearn.linear_model
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2


X = df1.iloc[:,1:7]
#X.astype('int')
Y = df1.iloc[:,-1]
Y = Y.astype('int')

best_feature = SelectKBest(score_func=chi2,k=6)
fit = best_feature.fit(X,Y)
dfscore = pd.DataFrame(fit.scores_)
dfcolumn = pd.DataFrame(X.columns)

#CONCATING
featureScores = pd.concat([dfcolumn,dfscore],axis=1)
featureScores.columns = ['Specification','Score']
print(featureScores.columns)
print(featureScores.nlargest(6,'Score'))

"""#**FEATURE IMPORTANCE**"""

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

import pandas as pd
import numpy as np
from sklearn.ensemble import ExtraTreesClassifier
import matplotlib.pyplot as plt


X1 = df1.iloc[:,1:7]
Y1 = df1.iloc[:,-1]
Y1 = Y1.astype('int')

model = ExtraTreesClassifier()
model.fit(X1,Y1)
print(model.feature_importances_)

feature_importance = pd.Series(model.feature_importances_, index =X.columns)
feature_importance.nlargest(6).plot(kind='barh')
plt.show()

"""# **HEAT-MAP**"""

import seaborn as sc

X2 = df1.iloc[:,1:7]
Y2 = df1.iloc[:,-1]

corrmat  = df1.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(6,6))

g= sc.heatmap(df1[top_corr_features].corr(),annot = True,cmap ="RdYlGn")

X_val = df1.iloc[:,1:7]
Y_val = df1.iloc[:,-1]
Y_val = Y_val.astype('int')

X_train,X_test,Y_train,Y_test = train_test_split(X_val,Y_val,test_size=0.35,random_state = 32)

"""#**FEATURE AFFECTING THE EMAIL STATUS**"""

!pip3 install seaborn==0.9.0

import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt

class_0 = df1.loc[df1['Email_Status'] == 0]['Word_Count']
class_1 = df1.loc[df1['Email_Status'] == 1]['Word_Count']
class_2 = df1.loc[df1['Email_Status'] == 2]['Word_Count']
plt.figure(figsize = (20,6))
plt.title('Total Word Count (Destiny Plot)')
#sn.set_color_codes(pastel)
sn.distplot(class_2,kde=True,bins=200, color='blue',label="2")
sn.distplot(class_1,kde=True,bins=200, color='red',label="1")
sn.distplot(class_0,kde=True,bins=200, color='green',label="0")
plt.show()

"""#**SVM**"""

from sklearn import svm
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score


X_val = df1.iloc[:,1:7]
Y_val = df1.iloc[:,-1]
Y_val = Y_val.astype('int')

X_train,X_test,Y_train,Y_test = train_test_split(X_val,Y_val,test_size=0.2,random_state = 32)

clf = svm.SVC(gamma='scale')
clf.fit(X_train,Y_train)

predic = clf.predict(X_test)
print(np.mean(predic ==Y_test))
import seaborn as sn
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

print(confusion_matrix(Y_test,predic))
sn.heatmap(confusion_matrix(Y_test,predic),annot=True,cmap='RdYlBu')
plt.show()

scores = cross_val_score(clf,X_val,Y_val,cv=6)
print("Cross Validation Score:",scores)

import pickle

filename='svm_svc.sav'
pickle.dump(clf,open(filename,'wb'))
loaded_model = pickle.load(open(filename,'rb'))
result = loaded_model.score(X_test,Y_test)
print(result)

final_pred = pd.read_csv("Test_09JmpYa.csv",usecols=['Email_Type','Subject_Hotness_Score','Email_Source_Type','Total_Past_Communications','Word_Count','Total_Links'])
final_pred = final_pred.dropna()
X_tr = final_pred
pred = clf.predict(X_tr)
print(pred)

"""#**FEATURE SCALING**"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
X_t = sc.fit_transform(X_train)
X_te = sc.transform(X_test)

"""# **DECISION TREE CLASSIFIER**"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score

dtree = DecisionTreeClassifier(max_depth =3).fit(X_train,Y_train)
dtree_predict = dtree.predict(X_test)
cm = confusion_matrix(Y_test,dtree_predict)
print(cm)
sn.heatmap(cm,annot=True,cmap='RdYlBu')
plt.show()
print(np.mean(dtree_predict ==Y_test))

import pickle

filename='d_tree.sav'
pickle.dump(dtree,open(filename,'wb'))
loaded_model = pickle.load(open(filename,'rb'))
result = loaded_model.score(X_test,Y_test)

final_pred = pd.read_csv("Test_09JmpYa.csv",usecols=['Email_Type','Subject_Hotness_Score','Email_Source_Type','Total_Past_Communications','Word_Count','Total_Links'])
final_pred = final_pred.dropna()
X_tr = final_pred
pred = dtree.predict(X_tr)
print(pred)

scores = cross_val_score(dtree,X_test,Y_test,cv=6)
print("Cross Validation Score:",scores)

"""#**KNN**"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score


knn = KNeighborsClassifier(n_neighbors =3).fit(X_train,Y_train)
accuracy = knn.score(X_test,Y_test)
print(accuracy)

knn_pred = knn.predict(X_test)
pp=confusion_matrix(Y_test,knn_pred)
print(pp)
sn.heatmap(confusion_matrix(Y_test,knn_pred),annot=True,cmap='RdYlBu')
plt.show()
print(np.mean(knn_pred == Y_test ))

scores = cross_val_score(knn,X_test,Y_test,cv=6)
print("Cross Validation Score:",scores)

!pip install scikit-multilearn
#import skmultilearn.naivebayes
!pip install scipy
#!pip install sklearn

"""# **XG BOOST**"""

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
import seaborn as sn
from sklearn.model_selection import cross_val_score

mode = XGBClassifier()
mode.fit(X_train,Y_train)
print(mode)

y_pred = mode.predict(X_test)
predictions = [round(value) for value in y_pred]

accuracy = accuracy_score(Y_test,predictions)
print(accuracy*100)
print(predictions)
print(confusion_matrix(Y_test,y_pred))
sn.heatmap(confusion_matrix(Y_test,y_pred),annot=True,cmap='RdYlBu')
plt.show()

scores = cross_val_score(mode,X_test,Y_test,cv=6)
print("Cross Validation Score:",scores)